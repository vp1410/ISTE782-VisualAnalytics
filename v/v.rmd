---
title: 'homework v'
author: 'Vivek Panchal,Rohit Kunjilikattil'
date: '2019-10-8'
output:
    pdf_document:
    latex_engine: xelatex
header-includes:
  \usepackage{booktabs}
---

```{r echo=FALSE}
# This chunk is just to make it possible to shrink the typeface in succeeding chunks. Mainly this will be used for the crosstabs.
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

# Introduction
In this assignment, we clean the NYC311 data to make sure it conforms to the tidy data standards. For this we use various tidyr functions like **separate** and **filter**. We transform the dataset into tidy data. Further we select another dataset, the nyc_payroll_information dataset, and clean that dataset so that it too follows the standards of tidy data. We have merged the two datasets using **Borough**.

Tidyverse is a r package that helps in making data tidy. Tidy data is defined as data which follows three basic rules : each variable must have its own column, each observation must have its own row and finally each value must have its own cell.One of the advantages of tidy data is it's easier to work with data that always has a consistent structure. Further, R's vectorised nature makes it particularly easy to transform tidy data.

```{r Installing packages}
library(tidyverse)
install.packages('tidyverse', repos = "http://cran.us.r-project.org")
library(data.table)
library(dplyr) 
```

```{r Reading csv file}
nyc311_a = fread("C:/Users/vivek 14/Downloads/311_Service_Requests_from_2010_to_Present.csv",nrows = 25000)
```

# Cleaning Data
Here, we first try to clean data as much as possible so that we do not have to waste our processing power on data that we don't want or on bad data. As the complaint type is one of the most important columns, we try to make it as uniform as possible. We go about doing this by removing any unwanted spaces, replacing hyphens with slashes, etc. We then filter the zipcodes to only have values of length 5. 

```{r Data Cleaning}
nyc311_a$Complaint.Type = tolower(nyc311_a$Complaint.Type) 
nyc311_a$Complaint.Type = gsub('s$', '', nyc311_a$Complaint.Type) 
nyc311_a$Incident.Zip = gsub('-[[:digit:]]{4}$', '',nyc311_a$Incident.Zip)
nyc311_a$Complaint.Type = gsub('paint - plaster', 'paint/plaster', nyc311_a$Complaint.Type)
nyc311_a$Complaint.Type = gsub('general construction', 'construction', nyc311_a$Complaint.Type)
nyc311_a$Complaint.Type = gsub('nonconst', 'construction', nyc311_a$Complaint.Type)
nyc311_a$Complaint.Type = gsub('street sign - [[:alpha:]]+', 'street sign', nyc311_a$Complaint.Type)
nyc311_a$Complaint.Type = gsub('fire alarm - .+','fire alarm', nyc311_a$Complaint.Type)
nyc311_clean2 = nyc311_a
```

# Separating Columns
Here, we see multiple columns that are of class character that have date and time values together in one column. So we use the **separate** function from tidyr library to separate such columns into separate columns with date and time stored separately.

```{r Creating seperate Columns for better analysis of data}
nyc311_clean2 <- nyc311_clean2 %>% 
  separate(`Created Date`, into = c("Created Date", "Created Time"), sep = 10)

nyc311_clean2 <- nyc311_clean2 %>% 
  separate(`Closed Date`, into = c("Closed Date", "Closed Time"), sep = 10)

nyc311_clean2 <- nyc311_clean2 %>% 
  separate(`Due Date`, into = c("Due Date", "Due Time"), sep = 10)

nyc311_clean2 <- nyc311_clean2 %>% 
  separate(`Resolution Action Updated Date`, into = c("Resolution Action Updated Date", "Resolution Action Updated Time"), sep = 10)
```

# Removing unwanted columns
Further we remove rows which have 'Unspecified' listed for Boroughs. Finally as all of this data is from New York City, we remove the city column as it is redundant. 

```{r Getting count of Complaints on basis of Incident Zip}
library(data.table)
nyc311_clean2 <- data.table(nyc311_clean2) 
nyc311_clean2 <- nyc311_clean2[,c("City"):=NULL]
nyc311_clean2 <- nyc311_clean2 %>% filter(!str_detect(Borough, "Unspecified"))
nyc311nodups<-distinct(nyc311_clean2)
isTRUE(all.equal(nyc311nodups,nyc311_clean2))
```

# Reading a dataset from a url
Here we use r to read and download the csv file directly from the url. The saves us the trouble of sharing the csv file along with the rmd file. This way is much more efficient. We are using NYC payroll data. This dataset contians the salary, pay rate and total compensation of every New York City employees from year 2014 till 2017.This dataset provides columns for fiscal year, agency they work for, borough they are working in.This will provide us with an insight into who gets paid how much and for what. The source dataset that we are extracting from url already follows the rules of tidydata. Hence, we do not use tidyr functions to further clean the data.

```{r Reading csv from URL}
nyc_payroll <- fread("https://data.cityofnewyork.us/api/views/k397-673e/rows.csv?accessType=DOWNLOAD",nrows = 25000)
nycpayroll_nodups<-distinct(nyc_payroll)
isTRUE(all.equal(nycpayroll_nodups,nyc_payroll))
```

There are 3 types of pay basis i.e Per hour, Per day and Per annum. We are trying to explore this by finding the total count of such employees working in New York city.

```{r Payment Categories}
nyc_payroll %>% dplyr::group_by(`Pay Basis`) %>% dplyr::summarise(n = n())

```

Here we have found out the total count of records by year.

```{r Count of records by year}
nyc_payroll %>% dplyr::group_by(`Fiscal Year`) %>% dplyr::summarise(n = n())
```

Showing first five records of the nyc_payroll dataset.

```{r payroll show head}
library(knitr)
nyc_payroll %>%
  head(5)%>%
  kable()
```

# Exploration of NYCPayroll dataset

In this part of analysis we have split our dataset into two parts, agencies that have income less than 10k and over 10k.

```{r Agency representation under 10k}
library(knitr)
library(dplyr)
byagencysub10<- nyc_payroll %>% count(nyc_payroll$`Agency Name`, nyc_payroll$`Fiscal Year`) %>% ungroup() %>% arrange(desc(n))
kable(head(byagencysub10,10))
```

Here we have represented agencies that have **Base Salary** more than 10K. We have made use of kable() of knitr library to display our data in a concise manner

```{r Agency representation over 10k }
library(knitr)
library(dplyr)
byunion10plus<- nyc_payroll %>% count(nyc_payroll$`Agency Name`,nyc_payroll$`Title Description`,nyc_payroll$`Base Salary`) %>% ungroup() %>% arrange(desc(n))
kable(head(byunion10plus,10))

```


We calculated the average salary of each agency in terms of `Regular Gross Paid`. We made use of dplyr functions for this analysis. We have grouped by the `Fiscal year` column of nycpayroll dataset.Mutate() helped us in creating a new variable from the data. The summarise_at() affects variables selected with character vector or vars().vars() is nothing but a character vector of column names, a numeric vector of column positions.

```{r Avg salary by Agency}
library(knitr)
library(dplyr)

salbyagency <- nyc_payroll %>%
  group_by(`Fiscal Year`) %>%
  mutate(Count = n()) %>%
  group_by(`Agency Name`, `Count`) %>%
  summarise_at(vars(`Regular Gross Paid`), funs(mean(., na.rm = TRUE))) %>%
  arrange(desc(`Regular Gross Paid`))
kable(head(salbyagency, 10))
```

In our dataset we have a column `Agency Start Date` so what we did is we created a new column `yrs` from it which has the year of that particular person when he started working. We made use of POSIXct for this purpose. Further to calculate experience we took out present date and from that we subtracted agency start date.We performed group by on Boroughs so that we get average years of experience of each Borough.
 
```{r summarize by borough and calculate average years of experience from Start Date - }
library(knitr)
library(lubridate)
library(dplyr)
nyc_payroll$`yrs` <- year(as.POSIXct(nyc_payroll$`Agency Start Date`, format="%d/%m/%Y"))
today <- format(Sys.Date(), "%Y")
nyc_payroll$exp <- as.numeric(today)-as.numeric(nyc_payroll$yrs)
salbyexp<- nyc_payroll%>%
  group_by(`Work Location Borough`) %>%
  select(`Work Location Borough`,exp) %>%
  dplyr::summarise_at(vars(`exp`), funs(mean(., na.rm=TRUE)))
kable(head(salbyexp,10))
```

As we are going to join our nyc payroll dataset with nyc311 open data set we have common columns such as Boroughs and Agency for that purpose we renamed our column name of `Work Location Borough` of nyc_payroll dataset to `Borough` so that we can perform merge operation.

```{r Renaming column}
library("magrittr")
library("data.table")
nyc_pr_br<-as.data.table(nyc_payroll) %>% {setnames(., old = "Work Location Borough", new = "Borough")[]}
```

We decided to join the databases upon the **Borough** column because it was the most obvious choice. The aim of this join was to add the average experience by borough calculated from the nyc_payroll database and use it to get the average experience for the agencies in the nyc311. The joined table contains the Agency name from the nyc311 database, the exp column from the nyc_payroll dataset and Borough which a common column, on which the join was performed.

```{r Joining datasets}
nyc_pr_exp<-as.data.table(salbyexp) %>% {setnames(., old = "Work Location Borough", new = "Borough")[]}
merged<- merge(nyc311_clean2,nyc_pr_exp, by='Borough',all.x = TRUE)
merged <- merged[,c(1,8,58)]
merged <- distinct(merged)
merged <- na.omit(merged)
head(merged)
```

# Data Dictionary
1. Borough - This is common column on which the join was performed. It specifies the Borough in which the complaint originated in the nyc311 dataset and it specifies the area in which a particular government job is in the nyc_payroll dataset

2. Agency Name - This is the name of the agency handling the problem.

3. exp - This is the average amount of experience by borough, calculated from the nyc_payroll data and then joined to the nyc311 data on the column 'Borough'


# Conclusion
In this assignment, we explored our NYC payroll dataset for better understanding. It helped us in understanding the pay scale of every agency that is operating in NYC. We used those statistics to calculate the average years of experience of people working in each Borough. Finally, we joined our NYC payroll dataset with nyc311 dataset and provided data dictionary for it.


